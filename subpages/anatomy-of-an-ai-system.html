<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Anatomy of an AI System</title>

<!--    Onest Font-->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Onest:wght@300..900&display=swap" rel="stylesheet">
<!-- Site's Favicon-->
<!--    citation: https://chatgpt.com/s/m_69332a4499788191bb6835e639079708 -->
<!--    chat citation: https://chatgpt.com/share/69332a74-f214-8003-a2cf-293196245e7a-->
    <link rel="icon" type="image/png" href="../static/favicon.png">
    <link rel="stylesheet" href="../mainStyles.css">
    <style>
        /* styling used for the button row with the view sources button and view the google form*/
        .button-row {
            display: flex;
            gap: 5pt; /* space between buttons */
            justify-content: center; /* centers them horizontally */
        }

    </style>
</head>
<body>


<!--    Back Button-->

    <div style="display: flex; justify-content: left; margin: 15pt 0 0 15pt;padding: 0; line-height: 1" >
        <a href="../index.html">
            <button class="button" style="font-size: 20pt;">
                üè†
            </button>
        </a>
    </div>
    <!--Header-->
    <div class="header">
        <h1>Anatomy of an AI System</h1>
        <h4>Word Count: 251</h4>
    </div>


<!--    horizontal line to divide from header-->
    <hr style="margin-top: 25pt; margin-bottom: 25pt;">
<!--    Response-->
    <div class="response">
        <p>This essay made me realise that any single request made to a device like the Amazon Echo, or Apple's HomePod,
            or anything that's a cloud-based "personal assistant" uses multiple resources, from server capacity, which
            needs to be cooled and maintained round the clock, your own broadband at home which you pay for, and even
            the physical materials required to construct the device, such as the lithium for the batteries, and so much
            more. These smart home devices operate in the same way in 2025, seven years later. However, with new
            technologies like the iPhone 15 Pro's A17 Pro chip, a shift is underway toward more "on-device" LLMs
            powered by Apple Intelligence ‚Äî coming soon to the EU, maybe (Servant of Cats).
        </p>

        <p>Personally, I don't use on-device LLMs usually,
            and I don't have an Echo, or similar product; however, I do treat ChatGPT like a search engine, as it works
            really well for quick answers, and it also gives sources; however, it is in no way mindful of the
            environment, and most likely uses more naturally occurring resources than the single use of an Echo. - If I
            could change one thing about our current AI / LLM data centres, it would be to have fewer trade-offs for a
            faster and more efficient quality of life. I am excited to one day run a full-size LLM locally on a small
            device in my pocket. People can currently run LLMs (of varying sizes) locally on their laptops/desktop
            computers; however, this is highly RAM-intensive and also draws significant power.
        </p>

    </div>
<!--empty div for padding-->
        <div style="padding: 10pt;">

        </div>
</body>
</html>




